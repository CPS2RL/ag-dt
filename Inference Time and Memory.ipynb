{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae2711-7d9c-4f04-9875-1f1ab19c2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('sunnyside_percent_25.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7165fa3-af42-41e3-94f4-abdac2bdadc6",
   "metadata": {},
   "source": [
    "# Inference Time Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df7432-c9ac-4604-91c8-5f989d973254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def measure_inference_time(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Measure inference time\n",
    "    \"\"\"\n",
    "    # Measure baseline overhead\n",
    "    c = 0\n",
    "    t1 = time.time()\n",
    "    for i in range(100):\n",
    "        x = 2\n",
    "    t1 = (time.time() - t1) / 100\n",
    "    \n",
    "    # Store timing results\n",
    "    arr = []\n",
    "    \n",
    "    # Process each test sample\n",
    "    for i in range(len(X_test[10])):\n",
    "        # Get single test sample\n",
    "        test_sample = X_test[i:i+1]  # Keep the batch dimension\n",
    "        \n",
    "        # Measure inference time with 50 iterations\n",
    "        t2 = time.time()\n",
    "        for _ in range(100):\n",
    "            _ = model.predict(test_sample, verbose=0)\n",
    "        t2 = (time.time() - t2) / 100\n",
    "        \n",
    "        # Calculate net inference time\n",
    "        inference_time = t2 - t1\n",
    "        arr.append(inference_time)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_time = np.mean(arr)\n",
    "    std_time = np.std(arr)\n",
    "    \n",
    "    print(\"\\nInference Time Statistics:\")\n",
    "    print(f\"Average inference time per sample: {avg_time:.4f} seconds\")\n",
    "    print(f\"Standard deviation: {std_time:.4f} seconds\")\n",
    "    print(f\"Min time: {min(arr):.4f} seconds\")\n",
    "    print(f\"Max time: {max(arr):.4f} seconds\")\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9573399-2267-46a4-914e-0445d9db0da1",
   "metadata": {},
   "source": [
    "# Memory Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469ca81-a4ff-42b9-b932-a281a21e2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import psutil\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "def measure_subset_memory_usage(model, X_test, start_idx=0, num_samples=100, num_runs=10):\n",
    "    \"\"\"\n",
    "    Measure memory usage for processing a subset of test data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : ML model object\n",
    "        The model to evaluate\n",
    "    X_test : numpy.ndarray\n",
    "        Test data\n",
    "    start_idx : int\n",
    "        Starting index for the subset\n",
    "    num_samples : int\n",
    "        Number of samples to include in the subset\n",
    "    num_runs : int\n",
    "        Number of times to repeat the measurement for reliability\n",
    "    \"\"\"\n",
    "    memory_results = []\n",
    "    \n",
    "    # Get test subset using array indexing\n",
    "    X_subset = X_test[start_idx:start_idx + num_samples]\n",
    "    \n",
    "    # Get baseline memory\n",
    "    baseline_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
    "    print(f\"Baseline memory: {baseline_memory:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nMeasuring memory usage for {len(X_subset)} samples ({num_runs} runs)...\")\n",
    "    \n",
    "    # Function to measure\n",
    "    def predict_subset():\n",
    "        return model.predict(X_subset)\n",
    "    \n",
    "    # Repeat measurement multiple times\n",
    "    for i in range(num_runs):\n",
    "        # Memory profiling for the subset\n",
    "        mem_usage = memory_usage(\n",
    "            (predict_subset, (), {}),\n",
    "            interval=0.005,  # Adjusted to 5ms sampling interval\n",
    "            max_iterations=1,\n",
    "            include_children=True\n",
    "        )\n",
    "        \n",
    "        # Calculate peak memory usage for this run\n",
    "        peak_memory = max(mem_usage) - baseline_memory\n",
    "        memory_results.append(peak_memory)\n",
    "        print(f\"Run {i+1}/{num_runs}: Peak memory usage: {peak_memory:.2f} MB\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    memory_stats = {\n",
    "        'mean': np.mean(memory_results),\n",
    "        'std': np.std(memory_results),\n",
    "        'min': np.min(memory_results),\n",
    "        'max': np.max(memory_results),\n",
    "        'per_sample_mean': np.mean(memory_results) / len(X_subset)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nMemory Usage Statistics (for subset):\")\n",
    "    print(f\"Subset size: {len(X_subset)} samples\")\n",
    "    print(f\"Average peak memory for subset: {memory_stats['mean']:.2f} MB\")\n",
    "    print(f\"Standard deviation: {memory_stats['std']:.2f} MB\")\n",
    "    print(f\"Min peak memory: {memory_stats['min']:.2f} MB\")\n",
    "    print(f\"Max peak memory: {memory_stats['max']:.2f} MB\")\n",
    "    print(f\"Average memory per sample: {memory_stats['per_sample_mean']:.4f} MB\")\n",
    "    \n",
    "    return {\n",
    "        'memory_results': memory_results,\n",
    "        'memory_stats': memory_stats,\n",
    "        'baseline_memory': baseline_memory,\n",
    "        'subset_size': len(X_subset)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcba7d0-df47-4ab0-be08-0d7318bed152",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdc3de-40ab-4235-bb35-01854293a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data\n",
    "df = data.copy()\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp_utc'], unit='s')\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], utc=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(['timestamp_utc', 'Senosor'], axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "df = df.ffill()\n",
    "\n",
    "# Encode the 'Class' column\n",
    "class_encoding = {'clean': 0, 'random': 1, 'malfunction': 2, 'drift': 3, 'bias': 4}\n",
    "df['Class'] = df['Class'].map(class_encoding)\n",
    "\n",
    "# Prepare data for TCN\n",
    "sequence_length = sequence_length\n",
    "features = df.drop(['timestamp', 'datetime', 'Class'], axis=1).values\n",
    "labels = df['Class'].values\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(len(df) - sequence_length):\n",
    "    X.append(features[i:i+sequence_length])\n",
    "    y.append(labels[i+sequence_length])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "# Convert labels to categorical\n",
    "num_classes = len(class_encoding)\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14229bb4-b862-43af-8d49-b1d68bb359c9",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c19b40-bb56-409d-b04c-baa4ad568af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Loading\n",
    "from tensorflow.keras.models import load_model\n",
    "resnet_model = load_model('ResNet.keras')\n",
    "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a4e6d-f6d0-41f3-a1b3-20cfa354187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting inference time measurement...\")\n",
    "inference_times = measure_inference_time(\n",
    "    model=resnet_model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "# Usage example:\n",
    "print(\"Starting memory profiling for subset...\")\n",
    "memory_metrics = measure_subset_memory_usage(\n",
    "    model=resnet_model,\n",
    "    X_test=X_test,\n",
    "    start_idx=0,\n",
    "    num_samples=20000,  \n",
    "    num_runs=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
